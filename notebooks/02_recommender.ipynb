{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender\n",
    "\n",
    "> This module exposes classes and functions related to training of the Word2Vec recommender using the Gensim library.\n",
    "\n",
    "https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "\n",
    "# adds library to context\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "import random\n",
    "from typing import List, NamedTuple, Tuple\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from word2vec_recommender.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class KnnRecommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        word_indexes: List[str],\n",
    "        embeddings: np.array,\n",
    "        n_recommendations: int = 10,\n",
    "        algorithm: str = 'brute'):\n",
    "\n",
    "        self.word_indexes = word_indexes\n",
    "        # https://stackoverflow.com/a/34145444 Normalize ensures euclidean will have the same output as cosine\n",
    "        self.embeddings = normalize(embeddings)\n",
    "        self._n_recommendations = n_recommendations\n",
    "\n",
    "        # create and fit embeddings index\n",
    "        self.nn_model: NearestNeighbors = NearestNeighbors(n_neighbors=self._n_recommendations+1, algorithm=algorithm)\n",
    "        self.nn_model.fit(self.embeddings)\n",
    "        \n",
    "        \n",
    "    def recommend_by_index(self, index: int) -> List[Recommendation]:\n",
    "        if not self.nn_model:\n",
    "            raise ValueError('you should call fit() before generating recommendations')\n",
    "        embedding = self.embeddings[index]\n",
    "        distances_array, indexes_array = self.nn_model.kneighbors([embedding])\n",
    "        recommendations = []\n",
    "        for ind, dist in zip(indexes_array[0][1:], distances_array[0][1:]):\n",
    "            recommendations.append( Recommendation(movie_id=int(self.word_indexes[ind]), score=dist))\n",
    "        return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading embeddings and words generated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"../data/best_model/embeddings.pkl\"), \"rb\") as f:\n",
    "    embeddings = np.load(f)\n",
    "with open(Path(\"../data/best_model/words_index.pkl\"), \"rb\") as f:\n",
    "    word_indexes = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_recommender = KnnRecommender(\n",
    "    word_indexes=word_indexes, \n",
    "    embeddings=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_repository = MovieRepository(pd.read_csv('../data/ml-latest-small/movies.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating recommendations\n",
    "\n",
    "> note that we need to find the index for a movie id in the embeddings array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie(movie_id=527, title=\"Schindler's List (1993)\", genres='Drama|War')\n",
      "> Recommendations:\n",
      ">> Movie(movie_id=50, title='Usual Suspects, The (1995)', genres='Crime|Mystery|Thriller') score=0.9987286925315857\n",
      ">> Movie(movie_id=593, title='Silence of the Lambs, The (1991)', genres='Crime|Horror|Thriller') score=1.0077788829803467\n",
      ">> Movie(movie_id=318, title='Shawshank Redemption, The (1994)', genres='Crime|Drama') score=1.0118942260742188\n",
      ">> Movie(movie_id=356, title='Forrest Gump (1994)', genres='Comedy|Drama|Romance|War') score=1.0190836191177368\n",
      ">> Movie(movie_id=2259, title='Blame It on Rio (1984)', genres='Comedy|Romance') score=1.0370359420776367\n",
      ">> Movie(movie_id=110, title='Braveheart (1995)', genres='Action|Drama|War') score=1.0436220169067383\n",
      ">> Movie(movie_id=2436, title='Tea with Mussolini (1999)', genres='Comedy|Drama|War') score=1.044758915901184\n",
      ">> Movie(movie_id=2028, title='Saving Private Ryan (1998)', genres='Action|Drama|War') score=1.0655676126480103\n",
      ">> Movie(movie_id=227, title='Drop Zone (1994)', genres='Action|Thriller') score=1.0666606426239014\n",
      ">> Movie(movie_id=1221, title='Godfather: Part II, The (1974)', genres='Crime|Drama') score=1.067683458328247\n"
     ]
    }
   ],
   "source": [
    "seed_id = int(word_indexes[10])\n",
    "recommendations = knn_recommender.recommend_by_index(10)\n",
    "print_recommendations(movie_repository, seed_id, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
