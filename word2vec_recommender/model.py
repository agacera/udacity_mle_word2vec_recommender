#AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_model.ipynb (unless otherwise specified).

__all__ = ['logger', 'GensimParameters', 'generate_sentences_by_user', 'Word2VecMovieModel', 'hyper_parameter_tunning']

#Cell
import logging
import random
from typing import List, NamedTuple, Tuple
from datetime import datetime
from itertools import product
from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from gensim.models import Word2Vec
from gensim.models.callbacks import CallbackAny2Vec

from .core import *

#Cell
logger = logging.getLogger(__name__)

#Cell
class GensimParameters(NamedTuple):
    window: int = 10
    iter: int = 20
    sg: int = 1
    hs: int = 0
    negative: int = 10
    alpha: float = 0.03
    min_alpha: float = 0.0007
    seed: int = 14
    compute_loss: bool = True

#Cell
def generate_sentences_by_user(df: pd.DataFrame):
    """
    Generate the Gensin sentences for a dataframe.
    Each sentence is created by joining all ratings from a user sorted by timestamp.
    """
    def to_sentence(r):
        return [str(m) for m in r]
    return df.groupby('userId')['movieId'].apply(to_sentence).tolist()

#Cell
class _EpochLogger(CallbackAny2Vec):
    """
    Log information about training, reports time for epochs.
    """
    def __init__(self, print_to_stdout: bool = False):
        """
        Constructor for the class to log progress information.
        """
        self._epoch = 1
        self._start = datetime.now()
        self._end = datetime.now()
        self._print_to_stdout = print_to_stdout

    def on_epoch_begin(self, _):
        """
        Print progress information, initializes start time.
        :param _: type gensim word2vec, signature to match the function to be used by gensim
        """
        self._start = datetime.now()
        msg = f"Epoch #{self._epoch} start"
        if self._print_to_stdout:
            print(msg)
        logger.info(msg)

    def on_epoch_end(self, model):
        """
        Print time to for epoch
        :param model: type gensim word2vec, signature to match the function to be used by gensim
        """
        self._end = datetime.now()
        elapsed = self._end - self._start
        msg = f"Epoch #{self._epoch} end in {elapsed} time"
        if self._print_to_stdout:
            print(msg)
        logger.info(msg)
        msg = f"Epoch #{self._epoch}, loss {model.get_latest_training_loss()}"
        if self._print_to_stdout:
            print(msg)
        logger.info(msg)
        self._epoch += 1


#Cell
class Word2VecMovieModel:
    """
    This class encapsulates the training of recommendations plus utilities for persistance and predictions
    """
    def __init__(
        self,
        movies_df: pd.DataFrame,
        ratings_df: pd.DataFrame,
        gensim_parameters: GensimParameters,
        positive_rating_threshold: float = 3.0,
        train_validation_ratio: float = 0.9
        ):

        self.movies_df = movies_df
        self.ratings_df = ratings_df
        self.gensim_parameters = gensim_parameters
        self.model: Word2Vec = None

        # joins movie and ratings df
        df_joined = ratings_df.set_index('movieId').join(movies_df.set_index('movieId'), on='movieId', rsuffix='movie_').reset_index()
        # keep only positive ratings
        df_joined = df_joined[df_joined['rating'] >= positive_rating_threshold]
        # sort by user interactions
        df_joined.sort_values(by=['userId', 'timestamp'], inplace=True)
        # train validation split
        user_ids = df_joined["userId"].unique().tolist()
        random.Random(RANDOM_SEED).shuffle(user_ids)
        training_size = int(0.9 * len(user_ids))
        training_user_ids = user_ids[:training_size]
        validation_user_ids = user_ids[training_size:]
        assert len(validation_user_ids) + len(training_user_ids) == len(user_ids)
        self.train_df = df_joined[df_joined['userId'].isin(training_user_ids)]
        self.validation_df = df_joined[df_joined['userId'].isin(validation_user_ids)]


    def __repr__(self):
        return f"movies={self.movies_df.shape}, ratings={self.ratings_df.shape}, " +\
            f"train_df={self.train_df.shape}, validation_df={self.validation_df.shape}"

    def train(self, print_progress: bool = False):
        sentences_train = generate_sentences_by_user(self.train_df)
        self.model = Word2Vec(sentences_train, callbacks=[_EpochLogger(print_to_stdout=print_progress)],  **self.gensim_parameters._asdict())

    def similar_by_movie_id(self, seed_movie_id: int, n: int = 5) -> List[Recommendation]:
        if str(seed_movie_id) not in self.model.wv:
            return []
        movie_embedding = self.model.wv[str(seed_movie_id)]
        movies = self.model.wv.similar_by_vector(movie_embedding, topn= n+1)[1:]
        return [ Recommendation(movie_id=int(m[0]), score=m[1]) for m in movies ]

    def save_all(self, output_path: Path):
        if not output_path.exists():
            output_path.mkdir()
        if not output_path.is_dir():
            raise ValueError(f"{output_path} should be a directory")
        word_indexes = self.model.wv.index2word
        embeddings = self.model.wv.vectors
        with open(output_path / 'words_index.pkl', 'wb') as f:
            np.save(f, word_indexes)
        with open(output_path / 'embeddings.pkl', 'wb') as f:
            np.save(f, embeddings)
        with open(output_path / 'model.gensim', 'wb') as f:
            self.model.save(f)


    def calculate_precision_at_k(self, k=10, debug=False) -> float:
        validation_sentences = generate_sentences_by_user(self.validation_df)
        validation_sentences = [ set(sentence) for  sentence in validation_sentences ]
        total_precision_at_k = 0.0
        for sentence in validation_sentences:
            n_sentences = len(sentence)
            n_matches = 0.0
            for movie_id in sentence:
                recs = {str(rec.movie_id) for rec in self.similar_by_movie_id(int(movie_id), n=k)}
                n_matches += len(sentence.intersection(recs)) / k
            precision_at_k = n_matches / n_sentences
            if debug:
                print(n_matches, n_sentences, precision_at_k)
            total_precision_at_k += precision_at_k
        return total_precision_at_k / len(validation_sentences)




#Cell
def hyper_parameter_tunning(epochs: List[int], windows: List[int], negatives: List[int], target_k: int, debug=False) -> Tuple[Word2VecMovieModel, GensimParameters, float]:
    best_model = None
    best_p = 0.0
    best_hyperparams = None
    for epoch, window, negative in product(epochs, windows, negatives):
        gensim_parameters = GensimParameters(compute_loss=False, window= window, iter=epoch, negative= negative)
        if debug:
            print("> Running for", gensim_parameters)
        model = Word2VecMovieModel(
            movies_df=movies_df,
            ratings_df=ratings_df,
            gensim_parameters=gensim_parameters
        )
        model.train()
        p = model.calculate_precision_at_k(target_k)
        if debug:
            print(f"p_at_{target_k}", p)
        if p > best_p:
            best_p = p
            best_model = model
            best_hyperparams = gensim_parameters
    if debug:
        print("> Best params ", best_p, best_hyperparams)
    return (best_model, best_hyperparams, best_p)