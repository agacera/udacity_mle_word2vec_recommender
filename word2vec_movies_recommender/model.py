#AUTOGENERATED! DO NOT EDIT! File to edit: dev/00_model.ipynb (unless otherwise specified).

__all__ = ['GensimParameters', 'generate_sentences_by_user', 'Word2VecMovieRecommender']

#Cell
class GensimParameters(NamedTuple):
    window: int = 10
    iter: int = 20
    sg: int = 1
    hs: int = 0
    negative: int = 10
    alpha: float = 0.03
    min_alpha: float = 0.0007
    seed: int = 14
    compute_loss: bool = True

#Cell
def generate_sentences_by_user(df: pd.DataFrame):
    """
    Generate the Gensin sentences for a dataframe
    Each sentence is created by joining all ratings from a user sorted by timestamp
    The expectation is that by doing this, the Search2Vec model will learn similar items based on their proximity.
    """
    def to_sentence(r):
        return [str(m) for m in r]
    return df.groupby('userId')['movieId'].apply(to_sentence).tolist()

#Cell
class Word2VecMovieRecommender:
    def __init__(
        self: Word2VecMovieRecommender,
        movies_df: pd.DataFrame,
        ratings_df: pd.DataFrame,
        gensim_parameters: GensimParameters,
        positive_rating_threshold: float = 3.0,
        train_validation_ratio: float = 0.9
        ):

        self.movies_df = movies_df
        self.ratings_df = ratings_df
        self.gensim_parameters = gensim_parameters
        self.movie_id_dict = movies_df.set_index("movieId").to_dict('index')
        self.model: Word2Vec = None

        # joins movie and ratings df
        df_joined = ratings_df.set_index('movieId').join(movies_df.set_index('movieId'), on='movieId', rsuffix='movie_').reset_index()
        # keep only positive ratings
        df_joined = df_joined[df_joined['rating'] >= positive_rating_threshold]
        # sort by user interactions
        df_joined.sort_values(by=['userId', 'timestamp'], inplace=True)
        # train validation split
        user_ids = df_joined["userId"].unique().tolist()
        random.Random(RANDOM_SEED).shuffle(user_ids)
        training_size = int(0.9 * len(user_ids))
        training_user_ids = user_ids[:training_size]
        validation_user_ids = user_ids[training_size:]
        assert len(validation_user_ids) + len(training_user_ids) == len(user_ids)
        self.train_df = df_joined[df_joined['userId'].isin(training_user_ids)]
        self.validation_df = df_joined[df_joined['userId'].isin(validation_user_ids)]


    def __repr__(self: Word2VecMovieRecommender):
        return f"movies={self.movies_df.shape}, ratings={self.ratings_df.shape}, " +\
            f"train_df={self.train_df.shape}, validation_df={self.validation_df.shape}"


    def train(self: Word2VecMovieRecommender, print_progress: bool = True):
        sentences_train =generate_sentences_by_user(self.train_df)
        self.model = Word2Vec(sentences_train, callbacks=[EpochLogger(print_to_stdout=print_progress)],  **self.gensim_parameters._asdict())

    def similar_by_movie_id(self: Word2VecMovieRecommender, seed_movie_id: int, n: int = 5) -> Tuple[str, List[str]]:
        def movie_to_str(mv, distance=None):
            return f"{mv['title']} - {mv['genres']} {distance}"
        movie = self.movie_id_dict[seed_movie_id]
        seed_movie = movie_to_str(movie)
        movie_embedding = self.model.wv[str(seed_movie_id)]
        movies = self.model.wv.similar_by_vector(movie_embedding, topn= n+1)[1:]

        similars = []
        for m in movies:
            movie_id = m[0]
            distance = m[1]
            movie = self.movie_id_dict.get(int(movie_id))
            if movie:
                similars.append(movie_to_str(movie, distance))
            else:
                similars.append(f"movie={movie_id} not found!")

        return (seed_movie, similars)



